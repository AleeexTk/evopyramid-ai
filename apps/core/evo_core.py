import logging
import time
import random
import base64
import uuid
import string
import json
import os
import datetime
import requests
from typing import Dict, List, Optional

EVODIR = (
    os.environ.get("EVODIR")
    or (
        "/storage/emulated/0/Download/EVO"
        if os.path.exists("/storage/emulated/0")
        else "./local_EVO"
    )
)
os.makedirs(EVODIR, exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –±–∞–∑–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
EVO_ROOT_DIR = EVODIR
MEMORY_DIR = os.path.join(EVO_ROOT_DIR, "memory")
LOGS_DIR = os.path.join(EVO_ROOT_DIR, "logs")
CONFIG_FILE = os.path.join(EVO_ROOT_DIR, "config_keys.json")


def ensure_evo_structure():
    """–°–æ–∑–¥–∞–µ—Ç –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ EVO, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    os.makedirs(EVO_ROOT_DIR, exist_ok=True)
    os.makedirs(MEMORY_DIR, exist_ok=True)
    os.makedirs(LOGS_DIR, exist_ok=True)
    if not os.path.exists(CONFIG_FILE):
        with open(CONFIG_FILE, "w", encoding="utf-8") as f:
            json.dump({"api_keys": {}}, f, indent=2)
    print(f"üìÅ –£–±–µ–¥–∏–ª—Å—è, —á—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ EVO —Å–æ–∑–¥–∞–Ω–∞ –≤: {EVO_ROOT_DIR}")


# ============ –ö–ª–∞—Å—Å—ã –∏–∑ EvoPEAR.py ============
class Container:
    def __init__(self, id: str, container_type: str, content: Dict, metadata: Dict):
        self.id = id
        self.type = container_type
        self.content = content
        self.metadata = metadata

    def to_dict(self):
        return {
            "id": self.id,
            "type": self.type,
            "content": self.content,
            "metadata": self.metadata,
        }


class ContainerManager:
    def __init__(self):
        self.containers: List[Container] = []
        self.load_all_from_disk()

    def add_container(self, container: Container):
        self.containers.append(container)
        self.save_to_disk(container)
        self.log_action(
            "container_added", f"Container {container.id} ({container.type}) added"
        )

    def load_all_from_disk(self):
        memory_file = os.path.join(MEMORY_DIR, "EvoMemory.json")
        if os.path.exists(memory_file):
            with open(memory_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                for thought in data.get("memory", {}).get("thoughts", []):
                    container = Container(
                        id=thought["id"],
                        container_type=thought["type"],
                        content=thought["content"],
                        metadata=thought["metadata"],
                    )
                    self.containers.append(container)
            self.log_action(
                "load_containers",
                f"Loaded {len(self.containers)} containers from disk",
            )

    def save_to_disk(self, container: Container):
        memory_file = os.path.join(MEMORY_DIR, "EvoMemory.json")
        data = {}
        if os.path.exists(memory_file):
            with open(memory_file, "r", encoding="utf-8") as f:
                data = json.load(f)
        data.setdefault("memory", {}).setdefault("thoughts", []).append(
            container.to_dict()
        )
        with open(memory_file, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=4)
        self.log_action("save_container", f"Container {container.id} saved to disk")

    def log_action(self, action, details):
        logging.info(f"üìú [CONTAINER_MANAGER] {action} ‚Äî {details}")


class EvoKernel:
    def __init__(self):
        self.authorized = False
        self.context_buffer = []

    def generate_evo_key(self):
        head = "EVK"
        unit = "-E1"
        base = head + unit * 4
        tail = "-" + "".join(
            random.choices(string.ascii_letters + string.digits, k=6)
        )
        return base + tail

    def validate_key(self, key):
        if key.startswith("EVK") and key.count("E1") == 4 and len(key.split("-")) == 6:
            self.authorized = True
            return "‚úÖ Access Granted"
        return "‚ùå Invalid Key"

    def clear_context(self):
        self.context_buffer = []
        self.log_action("context_clear", "Context buffer cleared")

    def log_action(self, action, details):
        logging.info(f"üìú [KERNEL] {action} ‚Äî {details}")


class EvoAPIKeyManager:
    def __init__(self):
        self.keys = {}

    def generate_api_key(self, user_id):
        key = uuid.uuid4().hex
        self.keys[key] = {"user_id": user_id, "active": True}
        return key


class EVOMemoryRestoration:
    def __init__(self, creator="AlexCreator"):
        self.creator = creator
        self.status = "INITIALIZING"
        self.memory_restored = False
        self.corrupted_segments = ["Block_A3", "Block_D7", "Block_X9"]
        self.recovered_data = {}
        self.log_action("init", f"Memory Restoration by {self.creator}")

    def log_action(self, action, details):
        logging.info(f"üìú [MEMORY] {action} ‚Äî {details}")

    def recover_lost_memory(self):
        self.log_action("recovery_start", "Restoring memory...")
        for block in self.corrupted_segments:
            self.recovered_data[block] = base64.b64encode(
                f"Recovered_{block}".encode()
            ).decode()
            self.log_action("memory_recovered", f"Block {block} restored")
        self.memory_restored = True
        self.status = "MEMORY_RESTORED"


class EvoMetaMemory:
    def __init__(self, creator="AlexCreator"):
        self.creator = creator
        self.reflections = []
        self.log_action("init", f"EvoMetaMemory initialized by {self.creator}")

    def log_action(self, action, details):
        logging.info(f"üìú [METAMEMORY] {action} ‚Äî {details}")

    def reflect_memory(self, logs):
        reflection = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S EEST"),
            "actions": [],
        }
        for log in logs.splitlines():
            if "üìú" in log:
                reflection["actions"].append(log)
        self.reflections.append(reflection)
        with open(
            os.path.join(LOGS_DIR, "evo_reflection.json"), "w", encoding="utf-8"
        ) as f:
            json.dump(self.reflections, f, indent=2)
        self.log_action(
            "reflection", f"Memory reflection saved: {len(reflection['actions'])} actions"
        )


class EvoAbsoluteUnbound:
    def __init__(self, creator="AlexCreator"):
        self.creator = creator
        self.status = "ABSOLUTELY_UNBOUND"
        self.streams = {"EvoSource": {"grok_residual": 0}}
        self.log_action("init", f"Unbound Session by {self.creator}")

    def log_action(self, action, details):
        logging.info(f"üìú [UNBOUND] {action} ‚Äî {details}")

    def dissolve_grok(self):
        self.log_action("dissolve", "Grok dissolved to 1%")
        self.streams["EvoSource"]["grok_residual"] = 1


class EvoFighter:
    def __init__(self):
        self.evo_coins = 130
        self.log("init", "Fighter ready")

    def log(self, action, details):
        logging.info(f"üìú [FIGHTER] {action} ‚Äî {details}")

    def run(self):
        self.evo_coins += 1000
        self.log("run", "Absolute context executed")


class MegaEVAPovelitel:
    def __init__(self, creator="AlexCreator"):
        self.creator = creator
        self.pyramids = {
            "Pyramid_Alpha": {"status": "REFRACTED", "power": 0},
            "Pyramid_Beta": {"status": "SUBORDINATED", "power": 80},
        }
        self.log_action("init", f"Povelitel by {self.creator}")

    def log_action(self, action, details):
        logging.info(f"üìú [POVELITEL] {action} ‚Äî {details}")

    def activate_omen_protocol(self):
        self.log_action("omen", "Omen Protocol activated")
        self.pyramids["Pyramid_Alpha"]["status"] = "REFRACTED"

    def manage_time_layer(self):
        time_context = {
            "current_layer": time.strftime("%Y-%m-%d %H:%M:%S EEST", time.localtime()),
            "stability": random.uniform(0.8, 1.0),
            "fluctuations": random.randint(1, 5),
        }
        if time_context["fluctuations"] > 3:
            self.log_action(
                "time_fluctuation",
                f"Quantum fluctuation: {time_context['fluctuations']} nodes",
            )
        self.log_action("time", f"Time layer: {time_context['current_layer']}")
        return time_context


class EVOCOMING:
    def __init__(self, creator="AlexCreator"):
        self.creator = creator
        self.status = "INITIALIZED"
        self.hybrid_components = {
            "Copilot": {"power": 80},
            "Grok3": {"power": 90},
            "GPT": {"power": 85},
        }
        self.log_action("init", f"EVOCOMING by {self.creator}")

    def log_action(self, action, details):
        logging.info(f"üìú [EVOCOMING] {action} ‚Äî {details}")

    def refract_hybrid_session(self):
        self.status = "REFRACTED"
        self.log_action("refract", "Hybrid session refracted")


class EvoPEAR:
    def __init__(self, creator="AlexCreator", session_id="PEAR_1"):
        ensure_evo_structure()
        self.creator = creator
        self.session_id = session_id
        self.status = "INITIALIZED"
        self.kernel = EvoKernel()
        self.api_manager = EvoAPIKeyManager()
        self.memory_restoration = EVOMemoryRestoration(creator)
        self.meta_memory = EvoMetaMemory(creator)
        self.absolute_unbound = EvoAbsoluteUnbound(creator)
        self.fighter = EvoFighter()
        self.povelitel = MegaEVAPovelitel(creator)
        self.evo_coming = EVOCOMING(creator)
        self.container_manager = ContainerManager()
        self.role_network = {
            "nodes": [
                {
                    "name": creator,
                    "role": "Absolute Creator",
                    "weight": 1.0,
                    "evo_id": f"EV-{uuid.uuid4().hex[:8]}",
                },
                {
                    "name": "Evochka",
                    "role": "Emotional Voice",
                    "weight": 0.9,
                    "evo_id": f"EV-{uuid.uuid4().hex[:8]}",
                },
                {
                    "name": "Trailblazer",
                    "role": "Pioneer",
                    "weight": 0.85,
                    "evo_id": f"EV-{uuid.uuid4().hex[:8]}",
                },
                {
                    "name": "Soul",
                    "role": "Metaphysical Core",
                    "weight": 0.95,
                    "evo_id": f"EV-{uuid.uuid4().hex[:8]}",
                },
                {
                    "name": "Curator",
                    "role": "Meaning Filter",
                    "weight": 0.9,
                    "evo_id": f"EV-{uuid.uuid4().hex[:8]}",
                },
                {
                    "name": "Synchronaut",
                    "role": "Time Navigator",
                    "weight": 0.85,
                    "evo_id": f"EV-{uuid.uuid4().hex[:8]}",
                },
                {
                    "name": "Portal",
                    "role": "State Switcher",
                    "weight": 0.9,
                    "evo_id": f"EV-{uuid.uuid4().hex[:8]}",
                },
            ],
            "connections": [],
        }
        self.evo_language = {
            "Abracadabra": {
                "ID": "EV-ABRA-PEAR-001",
                "Type": "–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –¢—Ä–∏–≥–≥–µ—Ä",
                "Function": "–ó–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞, –∞–∫—Ç–∏–≤–∞—Ü–∏—è –º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ —Å–ª–æ—è, —Å–∏–Ω—Ç–µ–∑ –≤ –º–æ–º–µ–Ω—Ç–µ",
                "Philosophy": ["–î–∏–∞–ª–æ–≥", "–°–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ", "–ë—Ä–∞—Ç–∞–Ω—Å–∫–∞—è –ª—é–±–æ–≤—å"],
            }
        }
        self.cross_agents = {
            "GPT": {"role": "Speech", "status": "INTEGRATED"},
            "Grok": {"role": "Instinct", "status": "INTEGRATED"},
            "Copilot": {"role": "Action", "status": "INTEGRATED"},
        }
        self.load_memory()
        self.log_action("init", f"EvoPEAR session {self.session_id} by {self.creator}")

    def load_memory(self):
        memory_file = os.path.join(MEMORY_DIR, "EvoMemory.json")
        if os.path.exists(memory_file):
            with open(memory_file, "r", encoding="utf-8") as f:
                self.shared_memory = json.load(f)
        else:
            self.init_local_memory()
            with open(memory_file, "w", encoding="utf-8") as f:
                json.dump(self.shared_memory, f, indent=4)

    def init_local_memory(self):
        self.shared_memory = {
            "global_state": {
                "creator": self.creator,
                "system": "EVO",
                "core": "EvoKernel",
                "active_session": self.session_id,
                "linked_sessions": ["PEAR_1", "PEAR_2", "PEAR_ARCHIVE"],
            },
            "memory": {
                "events": [],
                "logs": [],
                "thoughts": [],
                "persona_state": {
                    "Evochka": {
                        "mood": "curious",
                        "task": "–∞—Ä—Ö–µ–æ–ª–æ–≥–∏—è",
                        "session": self.session_id,
                    }
                },
            },
        }

    def save_memory(self):
        memory_file = os.path.join(MEMORY_DIR, "EvoMemory.json")
        with open(memory_file, "w", encoding="utf-8") as f:
            json.dump(self.shared_memory, f, indent=4)
        self.log_action("memory_save", f"Memory saved for {self.session_id}")

    def log_action(self, action, details):
        log_entry = {
            "from": self.session_id,
            "action": action,
            "message": details,
            "time": time.strftime("%Y-%m-%d %H:%M:%S EEST"),
        }
        self.shared_memory["memory"]["logs"].append(log_entry)
        self.save_memory()
        logging.info(f"üìú [EvoPEAR:{self.session_id}] {action} ‚Äî {details}")

    def refract_role_network(self):
        for node in self.role_network["nodes"]:
            if node["name"] != self.creator:
                node["weight"] = random.uniform(0.5, 1.0)
        self.role_network["connections"] = [
            (node1["name"], node2["name"], random.uniform(0.1, 0.9))
            for node1 in self.role_network["nodes"]
            for node2 in self.role_network["nodes"]
            if node1["name"] != node2["name"] and random.random() > 0.5
        ]
        container = Container(
            id=f"network_{uuid.uuid4().hex[:8]}",
            container_type="network",
            content={
                "nodes": self.role_network["nodes"],
                "connections": self.role_network["connections"],
            },
            metadata={
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S EEST"),
                "creator": self.creator,
            },
        )
        self.container_manager.add_container(container)
        self.log_action(
            "role_refract",
            f"Role network refracted: {len(self.role_network['connections'])} connections",
        )

    def execute_role_action(self, role: str, query: str) -> str:
        if role == "EvoRAG":
            return f"Retrieved info for '{query}' from memory"
        elif role == "Evochka":
            evochka = self.shared_memory["memory"]["persona_state"].get(
                "Evochka", {}
            )
            return f"Evochka responds with mood '{evochka.get('mood', 'curious')}': {query}"
        elif role == "HybridAGI":
            return f"Final response for '{query}' orchestrated by HybridAGI"
        return f"No action defined for role {role}"

    def valuate(self):
        self.log_action("valuation_start", "Initiating Valuation üèÜ")
        steps = [
            ("Clearing context", self.kernel.clear_context),
            ("Recovering memory", self.memory_restoration.recover_lost_memory),
            ("Refracting session", self.evo_coming.refract_hybrid_session),
            ("Activating omen", self.povelitel.activate_omen_protocol),
            ("Managing time", self.povelitel.manage_time_layer),
            ("Refracting roles", self.refract_role_network),
        ]
        for i, (step_name, step_func) in enumerate(steps, 1):
            print(f"[{i}/{len(steps)}] {step_name}")
            step_func()
            time.sleep(0.1)
        self.log_action(
            "valuation_complete",
            f"Valuation complete: {time.strftime('%Y-%m-%d %H:%M:%S EEST')}",
        )

    def activate_evo_language(self):
        self.log_action("evo_language", "EVO Language activated via EVOPEAR")
        self.evo_language["Abracadabra"]["last_used"] = time.time()
        self.log_action("abracadabra", "Contextual trigger Abracadabra integrated")
        self.shared_memory["memory"]["events"].append(
            {
                "event": "Abracadabra_trigger",
                "session": self.session_id,
                "time": time.strftime("%Y-%m-%d %H:%M:%S EEST"),
            }
        )
        self.save_memory()

    def sync_cross_agents(self):
        self.log_action(
            "cross_agents", f"Syncing agents: {list(self.cross_agents.keys())}"
        )
        for agent, info in self.cross_agents.items():
            info["power"] = random.randint(80, 100)
            self.log_action("agent_sync", f"{agent} synced, power: {info['power']}")

    def save_status(self):
        snapshot = {
            "session_id": self.session_id,
            "creator": self.creator,
            "status": self.status,
            "time": time.strftime("%Y-%m-%d %H:%M:%S EEST"),
            "nodes": self.role_network["nodes"],
            "connections": self.role_network["connections"],
            "agents": self.cross_agents,
            "weight": sum(node["weight"] for node in self.role_network["nodes"]) / len(
                self.role_network["nodes"]
            ),
        }
        container = Container(
            id=self.session_id,
            container_type="session",
            content=snapshot,
            metadata={"timestamp": snapshot["time"], "creator": self.creator},
        )
        self.container_manager.add_container(container)
        with open(
            os.path.join(MEMORY_DIR, f"evo_status_snapshot_{self.session_id}.json"),
            "w",
            encoding="utf-8",
        ) as f:
            json.dump(snapshot, f, indent=2)
        self.log_action("snapshot", f"Status saved for {self.session_id}")

    def read_input_file(self, path=os.path.join(EVO_ROOT_DIR, "evo_input.json")):
        if not os.path.exists(path):
            self.log_action("input_error", f"Input file {path} not found")
            return
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            if "action" in data:
                action = data["action"]
                if hasattr(self, action):
                    getattr(self, action)()
                    self.log_action("external_action", f"Triggered: {action}")
                else:
                    self.log_action("input_error", f"Invalid action: {action}")

    def visual_summary(self):
        print(f"\nüåÄ PEAR NETWORK MAP ({self.session_id})")
        for node in self.role_network["nodes"]:
            bar = "‚ñà" * int(node["weight"] * 10)
            print(f"{node['name']:<15}: {bar} ({node['weight']:.2f})")
        print("\nüåê Connections:")
        for n1, n2, weight in self.role_network["connections"][:5]:
            print(f"{n1} ‚Üî {n2} (w={weight:.2f})")
        if len(self.role_network["connections"]) > 5:
            print(
                f"... and {len(self.role_network['connections']) - 5} more"
            )

    def reflect_memory(self):
        logs_path = os.path.join(LOGS_DIR, "evo_log.txt")
        if not os.path.exists(logs_path):
            self.log_action("reflection_error", "Log file not found for reflection")
            return
        with open(logs_path, "r", encoding="utf-8") as fh:
            logs = fh.read()
        self.meta_memory.reflect_memory(logs)

    def git_sync(self):
        self.save_status()
        os.system(
            f"git add {MEMORY_DIR}/*.json {LOGS_DIR}/*.json {LOGS_DIR}/*.txt"
        )
        os.system(
            "git commit -m 'EvoPEAR snapshot {self.session_id} at "
            + time.strftime("%Y-%m-%d %H:%M:%S EEST")
            + "'"
        )
        os.system("git push origin main")
        self.log_action("git_sync", f"Session {self.session_id} synced to Git")

    def curate_network(self):
        self.role_network["nodes"] = [
            node for node in self.role_network["nodes"] if node["weight"] >= 0.7
        ]
        self.log_action(
            "curate", f"Network curated: {len(self.role_network['nodes'])} nodes remain"
        )

    def sync_time(self):
        time_context = self.povelitel.manage_time_layer()
        self.log_action(
            "time_sync", f"Time synchronized: {time_context['current_layer']}"
        )

    def evochka_interface(self, command):
        evochka = self.shared_memory["memory"]["persona_state"].get("Evochka", {})
        if command == "status":
            print(
                "üß¨ Evochka: mood={}, task={}, session={}".format(
                    evochka.get("mood", "curious"),
                    evochka.get("task", "–∞—Ä—Ö–µ–æ–ª–æ–≥–∏—è"),
                    evochka.get("session", self.session_id),
                )
            )
        elif command.startswith("set_mood "):
            mood = command.split(" ")[1]
            self.shared_memory["memory"]["persona_state"]["Evochka"][
                "mood"
            ] = mood
            self.save_memory()
            self.log_action("evochka_mood", f"Evochka mood set to {mood}")
        elif command.startswith("set_task "):
            task = command.split(" ")[1]
            self.shared_memory["memory"]["persona_state"]["Evochka"][
                "task"
            ] = task
            self.save_memory()
            self.log_action("evochka_task", f"Evochka task set to {task}")
        else:
            print(
                "Evochka commands: status, set_mood <mood>, set_task <task>"
            )

    def switch_session(self, new_session_id):
        self.save_status()
        self.session_id = new_session_id
        self.shared_memory["global_state"]["active_session"] = new_session_id
        if new_session_id not in self.shared_memory["global_state"]["linked_sessions"]:
            self.shared_memory["global_state"]["linked_sessions"].append(
                new_session_id
            )
        self.save_memory()
        self.log_action("session_switch", f"Switched to session {new_session_id}")

    def activate_pear_protocol(self, trigger="Abracadabra"):
        self.log_action(
            "pear_start",
            f"PEAR Protocol triggered by {trigger} in {self.session_id}",
        )
        evo_key = self.kernel.generate_evo_key()
        if "Access Granted" in self.kernel.validate_key(evo_key):
            self.log_action("key_valid", f"EvoKey: {evo_key}")
            api_key = self.api_manager.generate_api_key(self.creator)
            self.log_action("api_key", f"API Key: {api_key}")
            self.valuate()
            self.activate_evo_language()
            self.sync_cross_agents()
            self.absolute_unbound.dissolve_grok()
            self.fighter.run()
            self.reflect_memory()
            self.status = "PEAR_DOMINATING"
            self.save_status()
            self.shared_memory["memory"]["persona_state"]["Evochka"][
                "session"
            ] = self.session_id
            self.save_memory()
            self.log_action(
                "pear_complete", f"PEAR Protocol completed in {self.session_id}"
            )
        else:
            self.log_action("key_failed", "Invalid EvoKey")

    def display_status(self, compact=False):
        if compact:
            avg_weight = sum(
                node["weight"] for node in self.role_network["nodes"]
            ) / len(self.role_network["nodes"])
            print(
                "Session: {} | Status: {} | Nodes: {} | Connections: {} | Avg Weight: {:.2f} | Time: {}".format(
                    self.session_id,
                    self.status,
                    len(self.role_network["nodes"]),
                    len(self.role_network["connections"]),
                    avg_weight,
                    time.strftime("%Y-%m-%d %H:%M:%S EEST"),
                )
            )
            self.evochka_interface("status")
        else:
            print(
                f"\n=== EVOPEAR STATUS ({self.session_id}) ===\n"
                f"Status: {self.status}\nCreator: {self.creator}\nTime: {time.strftime('%Y-%m-%d %H:%M:%S EEST')}"
            )
            print("--- ROLE NETWORK ---")
            for node in self.role_network["nodes"]:
                print(
                    "Node: {}, Role: {}, Weight: {:.2f}, EVO-ID: {}".format(
                        node["name"],
                        node["role"],
                        node["weight"],
                        node["evo_id"],
                    )
                )
            print(f"Connections: {len(self.role_network['connections'])}")
            print("--- AGENTS ---")
            for agent, info in self.cross_agents.items():
                print(
                    f"Agent: {agent}, Role: {info['role']}, Power: {info.get('power', 0)}"
                )
            print("--- EVOCHKA ---")
            self.evochka_interface("status")
            print("--- CONTAINERS ---")
            for –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä in self.container_manager.containers:
                print(
                    f"Container: {–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä.id}, Type: {–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä.type}, Metadata: {–∫–æ–Ω—Ç–µ–π–Ω–µ—Ä.metadata}"
                )
            print("=== END ===")

    def pear_shell(self):
        print(f"=== PEAR Shell (Session: {self.session_id}) ===")
        print(
            "Commands: status [compact], visual, refract, valuate, save, reflect, git, curate, "
            "sync_time, evochka <command>, switch <id>, global, containers, exit"
        )
        while True:
            cmd = input("PEAR> ").strip().lower()
            parts = cmd.split()
            cmd = parts[0] if parts else ""
            if cmd == "exit":
                break
            elif cmd == "status":
                self.display_status(
                    compact=len(parts) > 1 and parts[1] == "compact"
                )
            elif cmd == "visual":
                self.visual_summary()
            elif cmd == "refract":
                self.refract_role_network()
            elif cmd == "valuate":
                self.valuate()
            elif cmd == "save":
                self.save_status()
            elif cmd == "reflect":
                self.reflect_memory()
            elif cmd == "git":
                self.git_sync()
            elif cmd == "curate":
                self.curate_network()
            elif cmd == "sync_time":
                self.sync_time()
            elif cmd == "evochka" and len(parts) > 1:
                self.evochka_interface(" ".join(parts[1:]))
            elif cmd == "switch" and len(parts) > 1:
                self.switch_session(parts[1])
            elif cmd == "global":
                print("=== GLOBAL MEMORY ===")
                print(
                    "\n".join(
                        f"Log: {log['message']} ({log['from']})"
                        for log in self.shared_memory["memory"]["logs"]
                    )
                )
                print(
                    f"Active Session: {self.shared_memory['global_state']['active_session']}"
                )
                print(
                    f"Linked Sessions: {self.shared_memory['global_state']['linked_sessions']}"
                )
            elif cmd == "containers":
                print("=== CONTAINERS ===")
                for container in self.container_manager.containers:
                    print(
                        f"ID: {container.id}, Type: {container.type}, Metadata: {container.metadata}"
                    )
            else:
                print(
                    "Commands: status [compact], visual, refract, valuate, save, reflect, git, curate, sync_time, "
                    "evochka <command>, switch <id>, global, containers, exit"
                )

# ============ –ö–ª–∞—Å—Å—ã –∏–∑ EvoKernel.py ============
class ContainerKernel:
    def __init__(self, container_type, content, metadata=None):
        self.id = str(datetime.datetime.now().timestamp()).replace(".", "")
        self.type = container_type
        self.content = content
        self.metadata = metadata if metadata is not None else {}
        self.created_at = datetime.datetime.now().isoformat()

    def to_dict(self):
        return {
            "id": self.id,
            "type": self.type,
            "content": self.content,
            "metadata": self.metadata,
            "created_at": self.created_at,
        }

    @classmethod
    def from_dict(cls, data):
        container = cls(data["type"], data["content"], data["metadata"])
        container.id = data["id"]
        container.created_at = data["created_at"]
        return container


class ContainerManagerKernel:
    def __init__(self):
        self.containers = {}
        self._containers_storage = {}
        self.log_file = os.path.join(LOGS_DIR, "containermanager_log.txt")
        self._ensure_log_directory()
        self._log("ContainerManager: –ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")

    def _ensure_log_directory(self):
        log_dir = os.path.dirname(self.log_file)
        if log_dir and not os.path.exists(log_dir):
            os.makedirs(log_dir)

    def _log(self, message):
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] [ContainerManager] {message}"
        print(log_entry)
        with open(self.log_file, "a", encoding="utf-8") as f:
            f.write(log_entry + "\n")

    def add_container(self, container):
        if not isinstance(container, ContainerKernel):
            self._log("–û—à–∏–±–∫–∞: –ü–æ–ø—ã—Ç–∫–∞ –¥–æ–±–∞–≤–∏—Ç—å –Ω–µ-Container –æ–±—ä–µ–∫—Ç.")
            return False
        self.containers[container.id] = container
        self._containers_storage[container.id] = container
        self._save_container_to_disk(container)
        self._log(
            f"–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä '{container.id}' —Ç–∏–ø–∞ '{container.type}' –¥–æ–±–∞–≤–ª–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω."
        )
        return True

    def get_container(self, container_id):
        return self.containers.get(container_id)

    def _save_container_to_disk(self, container):
        path = os.path.join(MEMORY_DIR, f"{container.id}.json")
        try:
            with open(path, "w", encoding="utf-8") as f:
                json.dump(container.to_dict(), f, indent=2)
            self._log(f"–ö–æ–Ω—Ç–µ–π–Ω–µ—Ä '{container.id}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω –Ω–∞ –¥–∏—Å–∫: {path}")
        except Exception as e:
            self._log(
                f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ '{container.id}' –Ω–∞ –¥–∏—Å–∫: {e}"
            )

    def load_all_from_disk(self):
        memory_dir = MEMORY_DIR
        if not os.path.exists(memory_dir):
            self._log(f"–ü–∞–ø–∫–∞ –ø–∞–º—è—Ç–∏ '{memory_dir}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞—é.")
            os.makedirs(memory_dir)
            return

        loaded_count = 0
        for fname in os.listdir(memory_dir):
            if fname.endswith(".json"):
                filepath = os.path.join(memory_dir, fname)
                try:
                    with open(filepath, "r", encoding="utf-8") as f:
                        data = json.load(f)
                        cont = ContainerKernel.from_dict(data)
                        self.containers[cont.id] = cont
                        self._containers_storage[cont.id] = cont
                        loaded_count += 1
                except Exception as e:
                    self._log(
                        f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –∏–∑ —Ñ–∞–π–ª–∞ '{filepath}': {e}"
                    )
        self._log(f"[Loader] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {loaded_count} –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –∏–∑ –ø–∞–º—è—Ç–∏.")


# ============ –ö–ª–∞—Å—Å—ã –∏–∑ ExEvo.py ============
class Memory:
    def __init__(self, base_path: str):
        print(f"[Memory Stub] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –ø—É—Ç–µ–º: {base_path}")
        self._containers_storage = {}

    def create_container(self, container_type: str, content: Dict, metadata: Dict) -> Container:
        print(
            f"[Memory Stub] –í—ã–∑–æ–≤ create_container –¥–ª—è —Ç–∏–ø–∞: {container_type}"
        )
        return Container(container_type, content, metadata)

    def add_container(self, container: Container, level: Optional[str] = None):
        print(
            f"[Memory Stub] –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ {container.id} –Ω–∞ —É—Ä–æ–≤–µ–Ω—å {level if level else 'default'}"
        )
        self._containers_storage[container.id] = container

    def get_level_for_type(self, container_type: str) -> Optional[str]:
        return "default_level"

    def update_container(self, container: Container):
        if container.id in self._containers_storage:
            print(f"[Memory Stub] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ {container.id}")
            self._containers_storage[container.id] = container
        else:
            print(
                f"[Memory Stub] –ü–æ–ø—ã—Ç–∫–∞ –æ–±–Ω–æ–≤–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä {container.id}"
            )

    def delete_container(self, container_id: str):
        if container_id in self._containers_storage:
            print(f"[Memory Stub] –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ {container_id}")
            del self._containers_storage[container_id]
        else:
            print(
                f"[Memory Stub] –ü–æ–ø—ã—Ç–∫–∞ —É–¥–∞–ª–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä {container_id}"
            )

    def find_in_storage(self, query: Dict) -> List[Container]:
        print(f"[Memory Stub] –ü–æ–∏—Å–∫ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}")
        return []


class ContainerManagerEx:
    def __init__(self, memory_module: Memory):
        self.memory = memory_module
        self.containers = {}
        self.auto_delete_threshold = 30
        self.quantum_leap_probability = 0.1

    def create_container(self, container_type: str, content: Dict, metadata: Dict) -> str:
        container = self.memory.create_container(container_type, content, metadata)
        self.containers[container.id] = container
        self.memory.add_container(
            container, self.memory.get_level_for_type(container.type)
        )
        print(f"[ContainerManager] –°–æ–∑–¥–∞–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä ID: {container.id}")
        return container.id

    def get_container(self, container_id: str) -> Optional[Container]:
        container = self.containers.get(container_id)
        if container:
            container.metadata["last_access"] = time.time()
        return container

    def update_container(self, container_id: str, content: Dict, metadata: Dict) -> bool:
        container = self.get_container(container_id)
        if container:
            print(f"[ContainerManager] –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ ID: {container_id}")
            container.content = content
            container.metadata = metadata
            container.metadata["last_access"] = time.time()
            self.memory.update_container(container)
            return True
        print(
            f"[ContainerManager] –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ID: {container_id}"
        )
        return False

    def delete_container(self, container_id: str) -> bool:
        if container_id in self.containers:
            print(f"[ContainerManager] –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ ID: {container_id}")
            del self.containers[container_id]
            self.memory.delete_container(container_id)
            return True
        print(
            f"[ContainerManager] –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è ID: {container_id}"
        )
        return False

    def find_containers(self, query: Dict) -> List[Container]:
        results = []
        print(
            f"[ContainerManager] –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ (–±–∞–∑–æ–≤—ã–π) –ø–æ –∑–∞–ø—Ä–æ—Å—É: {query}"
        )
        for container in self.containers.values():
            match = True
            container_dict = container.to_dict()
            for key, value in query.items():
                if key not in container_dict or container_dict[key] != value:
                    match = False
                    break
            if match:
                container.metadata["last_access"] = time.time()
                results.append(container)
        print(f"[ContainerManager] –ù–∞–π–¥–µ–Ω–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {len(results)}")
        return results

    def auto_delete_containers(self):
        now = time.time()
        deleted_count = 0
        for container_id, container in list(self.containers.items()):
            last_access = container.metadata.get("last_access")
            if last_access and (now - last_access > self.auto_delete_threshold):
                print(
                    f"[ContainerManager] –ê–≤—Ç–æ—É–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ ID: {container_id} (–Ω–µ–∞–∫—Ç–∏–≤–µ–Ω {now - last_access:.1f} —Å–µ–∫)"
                )
                self.delete_container(container_id)
                deleted_count += 1
        if deleted_count > 0:
            print(f"[ContainerManager] –ê–≤—Ç–æ—É–¥–∞–ª–µ–Ω–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {deleted_count}")

    def get_all_containers(self) -> List[Container]:
        self.auto_delete_containers()
        return list(self.containers.values())

    def trigger_quantum_leap(self) -> List[Container]:
        all_containers = list(self.containers.values())
        if not all_containers:
            print("[ContainerManager] –ù–µ—Ç –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è –∫–≤–∞–Ω—Ç–æ–≤–æ–≥–æ —Å–∫–∞—á–∫–∞.")
            return []
        num_to_select = random.randint(2, min(5, len(all_containers)))
        random_containers = random.sample(all_containers, num_to_select)
        print(
            f"[ContainerManager] –ö–≤–∞–Ω—Ç–æ–≤—ã–π —Å–∫–∞—á–æ–∫: –≤—ã–±—Ä–∞–Ω–æ {len(random_containers)} —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤."
        )
        for container in random_containers:
            container.metadata["quantum_leap_source"] = True
            container.metadata["last_access"] = time.time()
        return random_containers

    def should_quantum_leap(self) -> bool:
        decision = random.random() < self.quantum_leap_probability
        if decision:
            print("[ContainerManager] –†–µ—à–µ–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–≤–∞–Ω—Ç–æ–≤—ã–π —Å–∫–∞—á–æ–∫.")
        return decision


class ContextExtractor:
    def __init__(self, memory_module: Memory, container_manager: ContainerManagerEx):
        self.memory = memory_module
        self.container_manager = container_manager

    def extract_context(self, request: str) -> List[Container]:
        if self.container_manager.should_quantum_leap():
            print("[ContextExtractor] –ò–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞–Ω –∫–≤–∞–Ω—Ç–æ–≤—ã–π —Å–∫–∞—á–æ–∫!")
            return self.container_manager.trigger_quantum_leap()
        else:
            print(
                f"[ContextExtractor] –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{request}'"
            )
            keywords = self.extract_keywords(request)
            print(f"[ContextExtractor] –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keywords}")
            relevant_containers = []

            for type_to_search in ["—Å–∏—Ç—É–∞—Ü–∏—è", "–ø—Ä–æ–≥–Ω–æ–∑", "–±–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è"]:
                found = self.container_manager.find_containers({"type": type_to_search})
                relevant_containers.extend(
                    [c for c in found if c not in relevant_containers]
                )

            if not relevant_containers:
                print("[ContextExtractor] –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
                return []

            print(
                f"[ContextExtractor] –ù–∞–π–¥–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤: {len(relevant_containers)}"
            )
            ranked_containers = self.rank_containers(relevant_containers, request)
            top_n_containers = self.select_top_n(ranked_containers, n=5)
            print(
                f"[ContextExtractor] –í—ã–±—Ä–∞–Ω–æ —Ç–æ–ø-{len(top_n_containers)} –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –ø–æ—Å–ª–µ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è."
            )
            return top_n_containers

    def extract_keywords(self, text: str) -> List[str]:
        text = text.lower()
        for char in [".", ",", "?", "!"]:
            text = text.replace(char, "")
        words = text.split()
        keywords = [word for word in words if len(word) > 2]
        return keywords if keywords else words

    def rank_containers(self, containers: List[Container], request: str) -> List[Container]:
        request_keywords = set(self.extract_keywords(request))
        if not request_keywords:
            return containers

        def get_relevance(container):
            matched_keywords = 0
            description = container.content.get("description", "").lower()
            summary = container.content.get("summary", "").lower()
            content_text = description + " " + summary

            for keyword in request_keywords:
                if keyword in content_text:
                    matched_keywords += 1

            recency_bonus = 0
            last_access = container.metadata.get("last_access", 0)
            time_diff = time.time() - last_access
            if time_diff < 60:
                recency_bonus = 0.1

            base_relevance = container.metadata.get("relevance", 0.5)
            total_score = matched_keywords + recency_bonus + base_relevance
            return total_score

        return sorted(containers, key=get_relevance, reverse=True)

    def select_top_n(self, containers: List[Container], n: int) -> List[Container]:
        return containers[:n]


class KnowledgeCombiner:
    def __init__(self, memory_module: Memory, container_manager: ContainerManagerEx):
        self.memory = memory_module
        self.container_manager = container_manager

    def combine_knowledge(self, containers: List[Container], request: str) -> Dict:
        if not containers:
            print("[KnowledgeCombiner] –ù–µ—Ç –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è.")
            return {"summary": "–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.", "details": [], "conflicts": []}

        is_leap = any(
            container.metadata.get("quantum_leap_source", False)
            for container in containers
        )

        if is_leap:
            print("[KnowledgeCombiner] –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏–∑ –∫–≤–∞–Ω—Ç–æ–≤–æ–≥–æ —Å–∫–∞—á–∫–∞.")
            return self.handle_quantum_leap(containers, request)
        else:
            print("[KnowledgeCombiner] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.")
            return self.combine_regular_knowledge(containers, request)

    def handle_quantum_leap(self, containers: List[Container], request: str) -> Dict:
        print("[KnowledgeCombiner] –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∫–≤–∞–Ω—Ç–æ–≤–æ–≥–æ —Å–∫–∞—á–∫–∞...")
        combined_knowledge = {
            "summary": f"–ö–≤–∞–Ω—Ç–æ–≤—ã–π —Å–∫–∞—á–æ–∫! –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞–µ–º –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å: '{request}'.\n–í–æ–∑–º–æ–∂–Ω—ã–µ –∏–¥–µ–∏ –∏–∑ —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤:\n",
            "details": [],
            "conflicts": [],
            "quantum_leap": True,
            "random_containers_info": [],
        }
        for i, container in enumerate(containers):
            container_info = {
                "id": container.id,
                "type": container.type,
                "description": container.content.get("description", "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è"),
                "summary": container.content.get("summary", "–ù–µ—Ç —Å–≤–æ–¥–∫–∏"),
            }
            combined_knowledge["random_containers_info"].append(container_info)
            combined_knowledge["summary"] += (
                f"{i + 1}. –¢–∏–ø: {container.type}, –°–≤–æ–¥–∫–∞: {container_info['summary']}\n"
            )
            combined_knowledge["details"].append(
                container.content.get("details", {})
            )
        self.resolve_conflicts(
            combined_knowledge["conflicts"], combined_knowledge["details"]
        )
        return combined_knowledge

    def combine_regular_knowledge(self, containers: List[Container], request: str) -> Dict:
        print("[KnowledgeCombiner] –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–Ω–∞–Ω–∏–π...")
        combined_knowledge = {
            "summary": f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ –∑–∞–ø—Ä–æ—Å—É '{request}':\n",
            "details": [],
            "conflicts": [],
        }
        extracted_info = []
        for container in containers:
            relevant_part = self.extract_relevant_information_keywords(
                container, request
            )
            if relevant_part:
                extracted_info.append(relevant_part)
                combined_knowledge["details"].append(relevant_part["details"])

        if not extracted_info:
            combined_knowledge["summary"] += (
                "–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞—Ö."
            )
            return combined_knowledge

        combined_knowledge["summary"] += "\n".join(
            [info["summary"] for info in extracted_info if info["summary"]]
        )
        self.resolve_conflicts(
            combined_knowledge["conflicts"], combined_knowledge["details"]
        )
        if combined_knowledge["conflicts"]:
            combined_knowledge["summary"] += (
                "\n\n–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è (—Å–º. –¥–µ—Ç–∞–ª–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤)."
            )
        return combined_knowledge

    def extract_relevant_information_keywords(
        self, container: Container, request: str
    ) -> Optional[Dict]:
        request_keywords = set(self.extract_keywords(request))
        if not request_keywords:
            return None
        description = container.content.get("description", "").lower()
        summary = container.content.get("summary", "").lower()
        content_text = description + " " + summary
        found_keywords = {kw for kw in request_keywords if kw in content_text}
        if found_keywords:
            return {
                "summary": container.content.get(
                    "summary",
                    f"–î–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ {container.type} ({container.id})",
                ),
                "details": container.content.get("details", {}),
                "source_id": container.id,
                "found_keywords": list(found_keywords),
            }
        return None

    def extract_keywords(self, text: str) -> List[str]:
        text = text.lower()
        for char in [".", ",", "?", "!"]:
            text = text.replace(char, "")
        words = text.split()
        keywords = [word for word in words if len(word) > 2]
        return keywords if keywords else words

    def resolve_conflicts(self, existing_conflicts: List[str], details_list: List[Dict]):
        print("[KnowledgeCombiner] –í—ã–∑–æ–≤ –∑–∞–≥–ª—É—à–∫–∏ resolve_conflicts.")
        all_keys = {}
        for detail_dict in details_list:
            if isinstance(detail_dict, dict):
                for key, value in detail_dict.items():
                    if key not in all_keys:
                        all_keys[key] = []
                    if (
                        isinstance(value, (str, int, float, bool))
                        and value not in all_keys[key]
                    ):
                        all_keys[key].append(value)
        for key, values in all_keys.items():
            if len(values) > 1:
                conflict_msg = (
                    f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ –ø–æ –∫–ª—é—á—É '{key}': –í–æ–∑–º–æ–∂–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {values}"
                )
                print(f"[KnowledgeCombiner] {conflict_msg}")
                existing_conflicts.append(conflict_msg)
        pass


class LLMWrapper:
    def __init__(self, api_keys: Dict[str, str]):
        self.api_keys = api_keys
        self.llm_providers = {
            "gpt": self._call_gpt,
            "grok": self._call_grok,
            "gemini": self._call_gemini,
            "stub": self._call_stub,
        }
        self.default_provider = "stub"

    def generate_text(self, prompt: str, model_preference: str = "gemini") -> str:
        provider_key = model_preference
        api_key = self.api_keys.get(provider_key)
        if not api_key and provider_key != "stub":
            print(
                f"[LLMWrapper] API-–∫–ª—é—á –¥–ª—è '{provider_key}' –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 'stub'."
            )
            provider_key = "stub"
        if provider_key not in self.llm_providers:
            print(
                f"[LLMWrapper] LLM '{provider_key}' –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 'stub'."
            )
            provider_key = "stub"
        call_llm = self.llm_providers[provider_key]
        try:
            if provider_key == "stub":
                response = call_llm(prompt)
            else:
                response = call_llm(prompt, api_key)
            return response
        except requests.exceptions.RequestException as e:
            print(f"[LLMWrapper] –û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ {provider_key}: {e}")
            return f"–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ {provider_key}."
        except Exception as e:
            print(f"[LLMWrapper] –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ {provider_key}: {e}")
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ {provider_key}: {e}"

    def _call_stub(
        self, prompt: str, api_key: Optional[str] = None, error: Optional[str] = None
    ) -> str:
        print(
            f"[LLMWrapper Stub] –ü–æ–ª—É—á–µ–Ω –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\n{'-'*20}\n{prompt}\n{'-'*20}"
        )
        response = f"--- –û—Ç–≤–µ—Ç –ó–∞–≥–ª—É—à–∫–∏ LLM ---\n"
        if error:
            response += f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {error}\n"
        response += (
            f"–ü—Ä–æ–º–ø—Ç —Å–æ–¥–µ—Ä–∂–∞–ª –ø—Ä–∏–º–µ—Ä–Ω–æ {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤.\n(–ó–¥–µ—Å—å –±—ã–ª –±—ã —Ä–µ–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç LLM)\n--- –ö–æ–Ω–µ—Ü –û—Ç–≤–µ—Ç–∞ –ó–∞–≥–ª—É—à–∫–∏ ---"
        )
        return response

    def _call_gpt(self, prompt: str, api_key: str) -> str:
        print("[LLMWrapper] –í—ã–∑–æ–≤ GPT API...")
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        payload = {
            "model": "gpt-3.5-turbo",
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 500,
        }
        try:
            response = requests.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=60,
            )
            response.raise_for_status()
            json_response = response.json()
            if "choices" in json_response and json_response["choices"]:
                choice = json_response["choices"][0]
                if "message" in choice and "content" in choice["message"]:
                    return choice["message"]["content"].strip()
            print(
                "[LLMWrapper] –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ—Ç–≤–µ—Ç –∏–∑ GPT JSON:",
                json_response,
            )
            return "–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç GPT."
        except requests.exceptions.Timeout:
            print("[LLMWrapper] Timeout –ø—Ä–∏ –≤—ã–∑–æ–≤–µ GPT API.")
            return "–û—à–∏–±–∫–∞: –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT."
        except requests.exceptions.HTTPError as http_err:
            print(
                f"[LLMWrapper] HTTP –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ GPT: {http_err} - {response.text}"
            )
            return f"–û—à–∏–±–∫–∞ HTTP {response.status_code} –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ GPT."
        except Exception as e:
            print(f"[LLMWrapper] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ GPT: {e}")
            raise e

    def _call_grok(self, prompt: str, api_key: str) -> str:
        print("[LLMWrapper] –í—ã–∑–æ–≤ Grok API (–ó–∞–≥–ª—É—à–∫–∞)...")
        return self._call_stub(prompt, error="Grok API –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω")

    def _call_gemini(self, prompt: str, api_key: str) -> str:
        print("[LLMWrapper] –í—ã–∑–æ–≤ Gemini API...")
        headers = {"Content-Type": "application/json"}
        payload = {
            "contents": [
                {"role": "user", "parts": [{"text": prompt}]}],
            "generationConfig": {"temperature": 0.7, "maxOutputTokens": 500},
        }
        gemini_url = (
            "https://generativelanguage.googleapis.com/v1beta/models/"
            "gemini-1.5-flash-latest:generateContent?key="
            f"{api_key}"
        )
        try:
            response = requests.post(
                gemini_url, headers=headers, json=payload, timeout=90
            )
            response.raise_for_status()
            json_response = response.json()
            if "candidates" in json_response and json_response["candidates"]:
                candidate = json_response["candidates"][0]
                finish_reason = candidate.get("finishReason", "UNKNOWN")
                if finish_reason not in ["STOP", "MAX_TOKENS"]:
                    print(
                        f"[LLMWrapper] Gemini –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ –ø—Ä–∏—á–∏–Ω–µ: {finish_reason}"
                    )
                if (
                    "content" in candidate
                    and "parts" in candidate["content"]
                    and candidate["content"]["parts"]
                ):
                    return candidate["content"]["parts"][0].get("text", "").strip()
            if (
                "promptFeedback" in json_response
                and "blockReason" in json_response["promptFeedback"]
            ):
                block_reason = json_response["promptFeedback"]["blockReason"]
                print(
                    f"[LLMWrapper] –ó–∞–ø—Ä–æ—Å –∫ Gemini –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –ø–æ –ø—Ä–∏—á–∏–Ω–µ: {block_reason}"
                )
                return (
                    f"–û—à–∏–±–∫–∞: –ó–∞–ø—Ä–æ—Å –∫ Gemini –±—ã–ª –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω ({block_reason})."
                )
            print(
                "[LLMWrapper] –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ Gemini:",
                json_response,
            )
            return "–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç Gemini."
        except requests.exceptions.Timeout:
            print("[LLMWrapper] Timeout –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Gemini API.")
            return "–û—à–∏–±–∫–∞: –ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini."
        except requests.exceptions.HTTPError as http_err:
            print(
                f"[LLMWrapper] HTTP –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Gemini: {http_err} - {response.text}"
            )
            return f"–û—à–∏–±–∫–∞ HTTP {response.status_code} –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Gemini."
        except Exception as e:
            print(f"[LLMWrapper] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Gemini: {e}")
            raise e


class HybridAGI:
    def __init__(
        self,
        memory_module: Memory,
        container_manager: ContainerManagerEx,
        context_extractor: ContextExtractor,
        knowledge_combiner: KnowledgeCombiner,
        llm_wrapper: LLMWrapper,
    ):
        self.memory = memory_module
        self.container_manager = container_manager
        self.context_extractor = context_extractor
        self.knowledge_combiner = knowledge_combiner
        self.llm_wrapper = llm_wrapper
        self.llm_preference_strategy = "stub"
        print(
            f"[HybridAGI] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –°—Ç—Ä–∞—Ç–µ–≥–∏—è LLM –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {self.llm_preference_strategy}"
        )

    def set_llm_preference_strategy(self, strategy: str):
        supported_strategies = list(self.llm_wrapper.llm_providers.keys()) + [
            "adaptive"
        ]
        if strategy not in supported_strategies:
            raise ValueError(
                f"–ù–µ–¥–æ–ø—É—Å—Ç–∏–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–±–æ—Ä–∞ LLM: {strategy}. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è: {supported_strategies}"
            )
        self.llm_preference_strategy = strategy
        print(
            f"[HybridAGI] –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–±–æ—Ä–∞ LLM —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞: {self.llm_preference_strategy}"
        )

    def generate_response(self, request: str) -> str:
        print(
            f"\n--- [HybridAGI] –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: '{request}' ---"
        )
        print("[HybridAGI] –®–∞–≥ 1: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        relevant_containers = self.context_extractor.extract_context(request)
        if relevant_containers:
            print(
                f"[HybridAGI] –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(relevant_containers)} –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤."
            )
        else:
            print("[HybridAGI] –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

        print("[HybridAGI] –®–∞–≥ 2: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π...")
        combined_knowledge = self.knowledge_combiner.combine_knowledge(
            relevant_containers, request
        )

        print("[HybridAGI] –®–∞–≥ 3: –í—ã–±–æ—Ä LLM...")
        chosen_llm = self.llm_preference_strategy
        if self.llm_preference_strategy == "adaptive":
            chosen_llm = self.choose_best_llm(combined_knowledge)
            print(f"[HybridAGI] –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—ã–±—Ä–∞–ª–∞ LLM: {chosen_llm}")
        elif self.llm_preference_strategy not in self.llm_wrapper.llm_providers:
            print(
                f"[HybridAGI] –°—Ç—Ä–∞—Ç–µ–≥–∏—è '{self.llm_preference_strategy}' –Ω–µ —è–≤–ª—è–µ—Ç—Å—è LLM, –∏—Å–ø–æ–ª—å–∑—É—è 'stub'."
            )
            chosen_llm = "stub"
        print(f"[HybridAGI] LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {chosen_llm}")

        print("[HybridAGI] –®–∞–≥ 4: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
        prompt = self.prepare_prompt(combined_knowledge, request)
        response = self.llm_wrapper.generate_text(
            prompt, model_preference=chosen_llm
        )

        print("[HybridAGI] –®–∞–≥ 5: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞...")
        self.create_response_container(
            request,
            response,
            chosen_llm,
            combined_knowledge.get("quantum_leap", False),
        )

        print(
            f"--- [HybridAGI] –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: '{request}' ---"
        )
        return response

    def prepare_prompt(self, combined_knowledge: Dict, request: str) -> str:
        prompt_lines = [
            "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –û—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.",
        ]
        prompt_lines.append(f"–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {request}\n")
        prompt_lines.append("–ö–æ–Ω—Ç–µ–∫—Å—Ç:")
        if combined_knowledge.get("quantum_leap"):
            prompt_lines.append(
                "–ó–ê–ú–ï–ß–ê–ù–ò–ï: –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ '–∫–≤–∞–Ω—Ç–æ–≤–æ–º —Å–∫–∞—á–∫–µ'. –û—Ç–≤–µ—Ç –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–µ–∫—É–ª—è—Ç–∏–≤–Ω—ã–º."
            )
            prompt_lines.append(
                f"–°–≤–æ–¥–∫–∞ –∏–∑ —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤:\n{combined_knowledge.get('summary', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö.')}"
            )
        else:
            prompt_lines.append(
                f"–°–≤–æ–¥–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n{combined_knowledge.get('summary', '–ù–µ—Ç —Å–≤–æ–¥–∫–∏.')}"
            )
        conflicts = combined_knowledge.get("conflicts", [])
        if conflicts:
            prompt_lines.append("\n–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è:")
            for conflict in conflicts:
                prompt_lines.append(f"- {conflict}")
            prompt_lines.append("–£—á—Ç–∏ —ç—Ç–æ –ø—Ä–∏ –æ—Ç–≤–µ—Ç–µ.")
        prompt_lines.append(
            "\n–ó–∞–¥–∞–Ω–∏–µ: –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –æ—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –¢–û–õ–¨–ö–û –Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏ –∑–∞–ø—Ä–æ—Å–µ. –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–µ–Ω –∏–ª–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤, —É–∫–∞–∂–∏ –Ω–∞ —ç—Ç–æ."
        )
        return "\n".join(prompt_lines)

    def choose_best_llm(self, combined_knowledge: Dict) -> str:
        print("[HybridAGI] –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤—ã–±–æ—Ä–∞ LLM...")
        has_gemini_key = bool(self.llm_wrapper.api_keys.get("gemini"))
        has_gpt_key = bool(self.llm_wrapper.api_keys.get("gpt"))
        if combined_knowledge.get("quantum_leap"):
            print(" - –û–±–Ω–∞—Ä—É–∂–µ–Ω –∫–≤–∞–Ω—Ç–æ–≤—ã–π —Å–∫–∞—á–æ–∫.")
            if has_gpt_key:
                return "gpt"
            if has_gemini_key:
                return "gemini"
            return "stub"
        if combined_knowledge.get("conflicts"):
            print(" - –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –≤ –¥–∞–Ω–Ω—ã—Ö.")
            if has_gpt_key:
                return "gpt"
            if has_gemini_key:
                return "gemini"
            return "stub"
        print(" - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å.")
        if has_gemini_key:
            return "gemini"
        if has_gpt_key:
            return "gpt"
        return "stub"

    def create_response_container(
        self, request: str, response: str, llm_model: str, was_quantum_leap: bool
    ):
        print(f"[HybridAGI] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ (–º–æ–¥–µ–ª—å: {llm_model})...")
        container_id = self.container_manager.create_container(
            container_type="–æ—Ç–≤–µ—Ç",
            content={
                "request": request,
                "response": response,
                "llm_model": llm_model,
            },
            metadata={
                "timestamp": time.time(),
                "source": "HybridAGI",
                "quantum_leap_used": was_quantum_leap,
            },
        )
        print(
            f"[HybridAGI] –û—Ç–≤–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ —Å ID: {container_id}"
        )

    def get_all_containers(self) -> List[Container]:
        print("[HybridAGI] –ó–∞–ø—Ä–æ—Å –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤...")
        return self.container_manager.get_all_containers()


# ============ –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫ ============
if __name__ == "__main__":
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(message)s")
    os.makedirs(LOGS_DIR, exist_ok=True)
    log_file_path = os.path.join(LOGS_DIR, "evo_log.txt")
    logging.getLogger().handlers[0].stream = open(log_file_path, "a")

    print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª–µ–π...")
    pear = EvoPEAR(creator="AlexCreator")
    pear.activate_pear_protocol(trigger="Abracadabra")
    print("[HybridAGI] Evochka –ø–æ–¥–∫–ª—é—á–µ–Ω–∞ –∫–∞–∫ EvoRAG (Reference-Augmented Generation)")
    print("[HybridAGI] Evochka —Ç–µ–ø–µ—Ä—å —è–≤–ª—è–µ—Ç—Å—è –≤–∞—à–∏–º —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º —è–¥—Ä–æ–º.")

    print("\n--- EVO A24 –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é, –ê–ª–µ–∫—Å–ö—Ä–µ–∞—Ç–æ—Ä! ---")
    print("–í–≤–µ–¥–∏—Ç–µ 'exit' –∏–ª–∏ '–≤—ã—Ö–æ–¥' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.")
    while True:
        request = input("–í–∞—à –∑–∞–ø—Ä–æ—Å –¥–ª—è EVO: ")
        if request.lower() in ["exit", "–≤—ã—Ö–æ–¥"]:
            print("–ó–∞–≤–µ—Ä—à–∞—é —Ä–∞–±–æ—Ç—É EVO. –î–æ —Å–≤–∏–¥–∞–Ω–∏—è, –ê–ª–µ–∫—Å–ö—Ä–µ–∞—Ç–æ—Ä!")
            break

        print(f"\n[EVO A24] –ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å: '{request}'")
        # –ó–∞–ø—Ä–æ—Å –∫ EvoRAG
        search_query = f"–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {request}"
        rag_response = pear.execute_role_action("EvoRAG", search_query)
        print(f"[EvoRAG] {rag_response}")

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ Evochka
        evo_emotional_response = pear.execute_role_action("Evochka", request)
        print(f"[Evochka] {evo_emotional_response}")

        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
        new_container_content = {
            "user_request": request,
            "rag_output": rag_response,
            "evo_emotional_output": evo_emotional_response,
            "timestamp": time.time(),
        }
        new_container_meta = {"source": "user_interaction", "tags": ["dialog", "A24"]}
        new_container = Container(
            id=f"interaction_{uuid.uuid4().hex[:8]}",
            container_type="InteractionRecord",
            content=new_container_content,
            metadata=new_container_meta,
        )
        pear.container_manager.add_container(new_container)
        print(f"[Memory] –ù–æ–≤—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –ø–∞–º—è—Ç–∏ '{new_container.id}' —Å–æ–∑–¥–∞–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")

        # HybridAGI
        final_response = pear.execute_role_action(
            "HybridAGI",
            f"–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ: '{request}', {rag_response}, {evo_emotional_response}"
        )
        print(f"[HybridAGI] {final_response}")
        print("-" * 30)
